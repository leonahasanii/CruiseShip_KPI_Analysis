---
title: "Cruise Ships KPI Analysis"
author: "Leona Hasani"
date: "10.06.2024"
abstract: ""
format:
  html:                     
    standalone: true        
    embed-resources: true   
    code-fold: false        
    number-sections: true  
    toc: true 
highlight-style: github 
      
---
# Introduction

This report embarks on an exploratory analysis of the key performance indicators (KPIs) and trends for Vessel 1 and Vessel 2 throughout the year 2023. As the cruise industry sails into a future defined by sustainability and environmental responsibility, understanding the operational performance of these vessels becomes critical, not only for improving efficiency but also for ensuring compliance with upcoming regulations.

The European Union has set an ambitious target for all sectors, including maritime, to reach net-zero emissions by 2030 (B.V et al., 1970). This directive puts immense pressure on cruise companies to adapt and innovate, pushing them to rethink fuel consumption, emissions management, and overall operational strategies. For cruise liners, which are significant contributors to carbon emissions, this deadline marks a pivotal moment in their environmental and economic journey.

By analyzing the performance metrics of Vessel 1 and Vessel 2, this report will provide insights into their current operational status and identify key trends that could shape their path toward achieving the EU's sustainability goals. We will delve into essential factors such as fuel efficiency, emissions data, voyage durations, and environmental impacts, all of which play a crucial role in assessing whether these vessels are on track to contribute to the broader net-zero objective.

The exploratory nature of this analysis allows us to uncover not only areas of strength but also potential challenges that lie ahead. As the cruise industry moves toward a future where environmental sustainability is no longer optional, understanding these performance trends will help inform decisions, innovations, and strategic directions for both the present and the long-term goals of the companies involved.

In doing so, this report seeks to provide a holistic view of how Vessel 1 and Vessel 2 are currently performing and how their operations align with the evolving expectations of the industry and the regulatory landscape of the European Union.

# Data Overview

The dataset comprises detailed registrations recorded every 5 minutes over a one-year period for two vessels—Vessel 1 and Vessel 2—belonging to the Cruise Company. It covers the entire year of 2023, spanning from January 1st to December 31st.

To facilitate a deeper understanding of the dataset, a comprehensive description of each variable is available in the task_data folder, under the file named "schema.pdf". This document provides detailed insights into each parameter recorded in the dataset.

The dataset captures a wide array of operational metrics and environmental conditions, including key variables such as:

***Time and Location:*** 'Start Time', 'End Time', 'Latitude', 'Longitude', 'Local Time'

***Power Consumption:*** 'Power Galley 1 & 2', 'HVAC Chiller Power', 'Scrubber Power', 'Diesel Generator Power', 'Propulsion Power', 'Bow and Stern Thruster Power', and overall 'Total Power Consumption'

***Fuel Flow Rates:*** For boilers, incinerators, and main engines, including 'Boiler 1 & 2 Fuel Flow Rate' and 'Main Engine Fuel Flow Rates'

***Environmental Conditions:*** 'Sea Temperature', 'Relative and True Wind Speed and Direction'

***Performance Metrics:*** 'Speed Over Ground', 'Speed Through Water', 'Trim', 'Draft', and 'Duration'

This extensive dataset provides a robust foundation for exploring vessel performance, fuel consumption, environmental impact, and power usage across various systems onboard the vessels. By leveraging these variables, this analysis will offer valuable insights into operational efficiency and highlight areas where improvements can be made in line with the industry’s evolving environmental goals.

# Methodology

## Preprocessing steps

The dataset under examination comprises 44 variables and a total of 210,240 observations, with each observation representing measurements taken at five-minute intervals across various parameters. In the preprocessing stage, we first assessed the dataset for missing values, discovering that the variable "Depth (m)" contained over 27% of its observations as null. Given its negligible impact on the overall analysis and key performance indicators (KPIs), we opted to remove this variable entirely.

Subsequently, we found that the remaining variables each had less than 1% of their total observations missing. For these, we employed the Multiple Imputation by Chained Equations (MICE) technique to handle the missing data. MICE operates on the assumption that data is Missing At Random (MAR), which posits that the likelihood of a value being absent is contingent solely on observed values (Makaba & Dogo, 2019). This method iteratively predicts missing values based on the relationships among other variables in the dataset, employing regression models to generate multiple imputed values. Each missing variable is treated as a dependent variable, while the remaining data serves as independent variables. It is critical to recognize that applying MICE under non-MAR assumptions may yield biased results (Azur et al., 2011). Following this imputation process, the dataset was free of missing values.

We then converted the datetime information into the correct format and performed a thorough check for any duplicate observations, which could potentially compromise the integrity of our analysis. Fortunately, no duplicates were identified; if they had existed, we would have removed them to ensure a clean dataset.

With a complete dataset in hand, we computed the total power consumption by aggregating the power usage from various systems, including galleys, HVAC chillers, generators, and propulsion units. Additionally, we calculated the total fuel flow rates for all engines and boilers by summing their respective fuel consumption rates. We also identified key columns, such as 'Sea Temperature (Celsius)' and various speed measurements, adjusting their values by dividing by 288 to facilitate daily analysis. These transformations enhanced our capacity to conduct a detailed examination of power usage, fuel consumption patterns, and other operational metrics over time.

Lastly, we organized the data by grouping it according to vessel names—specifically 'Vessel 1' and 'Vessel 2'—and by day, resulting in the creation of a new dataset tailored for subsequent analyses. 

```{python}
#| label: importing the libraries
#| echo: false
#| message: false
#| include: false

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
from fancyimpute import IterativeImputer
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from scipy.stats import pearsonr

```

```{python}
#| label: importing the data
#| echo: false
#| message: false
#| include: false


data = pd.read_csv('task_data/data.csv', sep=",", header=0, index_col=False)
```


```{python}
#| label: data head
#| echo: false
#| message: false
#| include: false

data.head()
```


```{python}
#| label: data describe
#| echo: false
#| message: false
#| include: false

data.describe()
```


```{python}
#| label: data nunique
#| echo: false
#| message: false
#| include: false

data.nunique
```

```{python}
#| label: data info
#| echo: false
#| message: false
#| include: false

data.info()
```

```{python}
#| label: data NAs
#| echo: false
#| message: false
#| include: false

data.isna().sum()
```


```{python}
#| label: parse time
#| echo: false
#| message: false
#| include: false
# Parse Start Time and End Time columns to datetime format
data['Start Time'] = pd.to_datetime(data['Start Time'], format='%Y-%m-%dT%H:%M:%S')
data['End Time'] = pd.to_datetime(data['End Time'], format='%Y-%m-%dT%H:%M:%S')
```


```{python}
#| label: correlation matrix
#| echo: false
#| message: false
#| include: false
# Calculating the correlation matrix

corr_matrix = data.corr()

# Creating the correlation heatmap using plotly
fig = px.imshow(corr_matrix, 
                text_auto=True, 
                aspect="auto", 
                color_continuous_scale='Blues',
                title="Correlation Heatmap")

# Show the plot
fig.show()
```

```{python}
#| label: missing values heatmap
#| echo: false
#| message: false
#| include: false

# Create a heatmap of missing values
plt.figure(figsize=(12, 8))
sns.heatmap(data.isnull(), cbar=False, cmap='viridis')

# Show the plot
plt.title('Heatmap of Missing Values in the DataFrame')
plt.show()
```

```{python}
#| label: drop columns
#| echo: false
#| message: false
#| include: false


data = data.drop(columns=['Depth (m)'])
```

```{python}
#| label: heatmap of missing values
#| echo: false
#| message: false
#| include: false


# Create a heatmap of missing values
plt.figure(figsize=(12, 8))
sns.heatmap(data.isnull(), cbar=False, cmap='viridis')

# Show the plot
plt.title('Heatmap of Missing Values in the DataFrame')
plt.show()
```

```{python}
#| label: mice imputation
#| echo: false
#| message: false
#| include: false
#| eval: false 

# Identify columns with missing values
columns_with_na = data.columns[data.isnull().any()]

# Initialize the MICE imputer
mice_imputer = IterativeImputer()

# Apply MICE only to the columns with missing values
df_imputed = data.copy()  # Create a copy to keep the original DataFrame
df_imputed[columns_with_na] = mice_imputer.fit_transform(data[columns_with_na])

# Check the result
print(df_imputed.isnull().sum())  # This should show 0 missing values for all columns with missing values


```

```{python}
#| label: another heatmap of missing values
#| echo: false
#| message: false
#| include: false
#| eval: false 

plt.figure(figsize=(12, 8))
sns.heatmap(df_imputed.isnull(), cbar=False, cmap='viridis')

# Show the plot
plt.title('Heatmap of Missing Values in the DataFrame')
plt.show()

```

```{python}
#| label: save the imputed dataset to the local file
#| echo: false
#| message: false
#| include: false
#| eval: false 


df_imputed.to_csv('task_data/df_imputed.csv', index=False)

```

```{python}
#| label: read the imputed dataset
#| echo: false
#| message: false


df = pd.read_csv('task_data/df_imputed.csv', sep=",", header=0, index_col=False)

```

```{python}
#| label: look again at the missing values heatmap
#| echo: false
#| message: false
#| include: false
#| eval: false 

plt.figure(figsize=(12, 8))
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')

# Show the plot
plt.title('Heatmap of Missing Values in the DataFrame')
plt.show()

```

```{python}
#| label: check for duplicate rows
#| echo: false
#| message: false
#| include: false
#| eval: false 

# Check for duplicates across all columns
duplicate_rows = df[df.duplicated()]


# Check how many duplicates exist
print(f"Number of duplicate rows: {duplicate_rows.shape[0]}")
```

```{python}
#| label: Boxplots of numerical variables
#| echo: false
#| message: false


# Create a list of numerical variables
numerical_columns = df.select_dtypes(include='number').columns

# Melt the DataFrame to long format for FacetGrid
df_melted = df.melt(value_vars=numerical_columns, var_name='Feature', value_name='Value')

# Create a FacetGrid with boxplots for each numerical variable
g = sns.FacetGrid(df_melted, col='Feature', col_wrap=4, height=4, sharex=False, sharey=False)

# Map the boxplot while ensuring we correctly define the axes
g.map_dataframe(sns.boxplot, x='Value', color='skyblue')

g.set_titles(col_template="{col_name}")
g.set_axis_labels('Value', 'Feature')
plt.subplots_adjust(top=0.9)
g.fig.suptitle('Boxplots of Numerical Features', fontsize=16)

plt.show()
```

```{python}
#| label: parse time and do calculations of the totals
#| echo: false
#| message: false
#| include: false


# Parse Start Time and End Time columns to datetime format
df['Start Time'] = pd.to_datetime(df['Start Time'], format='%Y-%m-%dT%H:%M:%S')
df['End Time'] = pd.to_datetime(df['End Time'], format='%Y-%m-%dT%H:%M:%S')

# Create a new column to calculate the duration of each measurement interval in minutes
df['Duration (Minutes)'] = (df['End Time'] - df['Start Time']).dt.total_seconds() / 60

# Example of calculating total power consumption over each interval
df['Total Power Consumption (MW)'] = (
    df['Power Galley 1 (MW)'] + 
    df['Power Galley 2 (MW)'] + 
    df['Power Service (MW)'] + 
    df['HVAC Chiller 1 Power (MW)'] + 
    df['HVAC Chiller 2 Power (MW)'] + 
    df['HVAC Chiller 3 Power (MW)'] + 
    df['Scrubber Power (MW)'] + 
    df['Diesel Generator 1 Power (MW)'] +
    df['Diesel Generator 2 Power (MW)'] +
    df['Diesel Generator 3 Power (MW)'] +
    df['Diesel Generator 4 Power (MW)'] +
    df['Propulsion Power (MW)'] + 
    df['Port Side Propulsion Power (MW)'] + 
    df['Starboard Side Propulsion Power (MW)'] + 
    df['Bow Thruster 1 Power (MW)'] + 
    df['Bow Thruster 2 Power (MW)'] + 
    df['Bow Thruster 3 Power (MW)'] + 
    df['Stern Thruster 1 Power (MW)'] + 
    df['Stern Thruster 2 Power (MW)']
)

df['All Engines Fuel Flow Rate (kg/h)'] = (
  df['Main Engine 1 Fuel Flow Rate (kg/h)'] +
  df['Main Engine 2 Fuel Flow Rate (kg/h)'] +
  df['Main Engine 3 Fuel Flow Rate (kg/h)'] +
  df['Main Engine 4 Fuel Flow Rate (kg/h)']
)

df['All Boiler Fuel Flow Rate (L/h)'] = (
  df['Boiler 1 Fuel Flow Rate (L/h)'] +
  df['Boiler 2 Fuel Flow Rate (L/h)']
)

# Group by time intervals to analyze patterns
#df.set_index('Start Time', inplace=True)

```


```{python}
#| label: dataset overview
#| echo: false
#| message: false
#| include: false
#| eval: false 

df.head()
```



```{python}
#| label: group by date and vessel name
#| echo: false
#| message: false
#| include: false

# Extract the date from the Start Time column
df['Date'] = df['Start Time'].dt.date

# Group by both Date and Vessel Name, and then sum the numeric columns
df_grouped_by_day_vessel = df.groupby(['Date', 'Vessel Name']).sum(numeric_only=True).reset_index()

# Display the first few rows of the grouped DataFrame
print(df_grouped_by_day_vessel.head())

```


```{python}
#| label: group by date and vessel name dataset head
#| echo: false
#| message: false
#| include: false
#| eval: false 

df_grouped_by_day_vessel
```

```{python}
#| label: group by date and vessel name dataset columns
#| echo: false
#| message: false
#| include: false
#| eval: false 

print(df_grouped_by_day_vessel.columns)
```

```{python}
#| label: group by date and vessel name dataset division
#| echo: false
#| message: false
#| include: false


# Define the columns you want to divide by 288
columns_to_divide = ['Sea Temperature (Celsius)', 'Speed Over Ground (knots)', 'True Wind Speed (knots)', 'Relative Wind Speed (knots)', 'Speed Through Water (knots)']

# Apply division by 288 for the specified columns
df_grouped_by_day_vessel[columns_to_divide] = df_grouped_by_day_vessel[columns_to_divide].div(288)

# Display the updated DataFrame
print(df_grouped_by_day_vessel.head())

```

```{python}
#| label: group by date and vessel name dataset head2
#| echo: false
#| message: false
#| include: false
#| eval: false 

df_grouped_by_day_vessel.head()
```

```{python}
#| label: group by date and vessel name column removal
#| echo: false
#| message: false
#| include: false


# List of the columns I want to remove
columns_to_remove = [
    'Latitude (Degrees)',
    'Longitude (Degrees)',
    'Relative Wind Angle (Degrees)',
    'True Wind Angle (Degrees)',
    'Relative Wind Direction (Degrees)',
    'True Wind Direction (Degrees)',
    'Draft (m)',
    'Local Time (h)',
    'Trim (m)'
]

# Drop the columns you don't want
new_df = df_grouped_by_day_vessel.drop(columns=columns_to_remove, axis=1)

# Display the updated DataFrame
new_df.head()

```

```{python}
#| label: new dataset
#| echo: false
#| message: false
#| include: false
#| eval: false 

new_df
```

```{python}
#| label: diving the day into parts
#| echo: false
#| message: false
#| include: false
#| eval: false 

# Define the bins and labels with adjusted bin edges to avoid overlaps
bins = [0, 5, 8, 11, 12, 15, 17, 19, 21, 24]
labels = ['Night', 'Early Morning', 'Late Morning', 'Morning', 'Early Afternoon', 'Late Afternoon', 'Early Evening', 'Evening', 'Night']

# Ensure 'Start Time' is in datetime format
data['Start Time'] = pd.to_datetime(data['Start Time'])

# Create a new column 'Hour' by extracting the hour from 'Start Time'
data['Hour'] = data['Start Time'].dt.hour

# Use pd.cut to categorize the parts of the day
data['Part of Day'] = pd.cut(data['Hour'], bins=bins, labels=labels, right=False, include_lowest=True, ordered=False)

# Extract the date from 'Start Time' for grouping
data['Date'] = data['Start Time'].dt.date

# Group by Date, Vessel Name, and Part of Day, then sum the numerical columns
df_grouped_by_part_of_day = data.groupby(['Date', 'Vessel Name', 'Part of Day']).sum(numeric_only=True).reset_index()

# Display the first few rows of the new DataFrame
print(df_grouped_by_part_of_day.head())

# Optionally, check how many unique combinations we have
print(df_grouped_by_part_of_day[['Date', 'Vessel Name', 'Part of Day']].drop_duplicates().shape)

```


```{python}
#| label: group by part of the day info
#| echo: false
#| message: false
#| include: false
#| eval: false 

df_grouped_by_part_of_day.info()
```


```{python}
#| label: grouped by part of the day dataset
#| echo: false
#| message: false
#| include: false
#| eval: false 


df_grouped_by_part_of_day
```

# Descriptive Statistics

```{python}
#| label: group by only of the day dataframe
#| echo: false
#| message: false
#| include: false
#| eval: false 

df_grouped_by_day_vessel
```

# Performance Analysis

## Total Power Consumption (MW)


```{python}
#| label: Plot1
#| echo: false
#| message: false

# Assuming df is your dataset with power and fuel variables

plt.figure(figsize=(12, 6))

sns.lineplot(data=df, x='Date', y='Total Power Consumption (MW)', hue='Vessel Name', palette='Set1')

# Step 3: Set plot labels and title
plt.xlabel('Date')
plt.ylabel('Total Power Consumption (MW)')
plt.title('Total Power Consumption Over Time by Vessel')
plt.xticks(rotation=45)
plt.legend(title='Vessel')

# Step 4: Display the plot
plt.tight_layout()
plt.show()
```

```{python}
#| label: Plot2
#| echo: false
#| message: false

plt.figure(figsize=(12, 6))

sns.lineplot(data=df_grouped_by_day_vessel, x='Date', y='Total Power Consumption (MW)', hue='Vessel Name', palette='Set1')

# Step 3: Set plot labels and title
plt.xlabel('Date')
plt.ylabel('Total Power Consumption (MW)')
plt.title('Total Power Consumption Over Time by Vessel')
plt.xticks(rotation=45)
plt.legend(title='Vessel')

# Step 4: Display the plot
plt.tight_layout()
plt.show()
```

```{python}
#| label: Plot3
#| echo: false
#| message: false

# Define the power source columns to sum for each vessel
power_sources = [
    'Power Galley 1 (MW)', 
    'Power Galley 2 (MW)', 
    'Power Service (MW)', 
    'HVAC Chiller 1 Power (MW)', 
    'HVAC Chiller 2 Power (MW)', 
    'HVAC Chiller 3 Power (MW)', 
    'Scrubber Power (MW)', 
    'Diesel Generator 1 Power (MW)',
    'Diesel Generator 2 Power (MW)',
    'Diesel Generator 3 Power (MW)',
    'Diesel Generator 4 Power (MW)',
    'Propulsion Power (MW)', 
    'Port Side Propulsion Power (MW)', 
    'Starboard Side Propulsion Power (MW)', 
    'Bow Thruster 1 Power (MW)', 
    'Bow Thruster 2 Power (MW)', 
    'Bow Thruster 3 Power (MW)', 
    'Stern Thruster 1 Power (MW)', 
    'Stern Thruster 2 Power (MW)'
]

# Calculate total power consumption for each vessel
power_source_totals_vessel_1 = [df[df['Vessel Name'] == 'Vessel 1'][source].sum() for source in power_sources]
power_source_totals_vessel_2 = [df[df['Vessel Name'] == 'Vessel 2'][source].sum() for source in power_sources]

# Create pie chart for Vessel 1
fig_vessel_1 = go.Figure(data=[go.Pie(
    labels=power_sources,
    values=power_source_totals_vessel_1,
    hole=0.3,  # Create a donut chart by setting a hole
    hoverinfo='label+value+percent',  # Show label, value, and percentage on hover
)])

# Update layout for Vessel 1
fig_vessel_1.update_layout(
    title='Contribution of Power Sources to Total Power Consumption (MW) - Vessel 1',
    height=600,
    width=800,
    template='plotly_white'
)

# Show the plot for Vessel 1
fig_vessel_1.show()

# Create pie chart for Vessel 2
fig_vessel_2 = go.Figure(data=[go.Pie(
    labels=power_sources,
    values=power_source_totals_vessel_2,
    hole=0.3,  # Create a donut chart by setting a hole
    hoverinfo='label+value+percent',  # Show label, value, and percentage on hover
)])

# Update layout for Vessel 2
fig_vessel_2.update_layout(
    title='Contribution of Power Sources to Total Power Consumption (MW) - Vessel 2',
    height=600,
    width=800,
    template='plotly_white'
)

# Show the plot for Vessel 2
fig_vessel_2.show()
```



```{python}
#| label: Plot4
#| echo: false
#| message: false

# Step 1: Set the figure size
plt.figure(figsize=(12, 6))

# Step 2: Create the line plot
sns.lineplot(data=df, x='Date', y='All Engines Fuel Flow Rate (kg/h)', hue='Vessel Name', palette='Set1')

# Step 3: Set plot labels and title
plt.xlabel('Date')
plt.ylabel('Total Fuel Flow Rate (kg/h)')
plt.title('Total Fuel Flow Rate Over Time by Vessel')
plt.xticks(rotation=45)
plt.legend(title='Vessel')

# Step 4: Display the plot
plt.tight_layout()
plt.show()
```

```{python}
#| label: Plot5
#| echo: false
#| message: false

plt.figure(figsize=(12, 6))

# Assuming df_grouped_by_day_vessel is a pre-grouped DataFrame
sns.lineplot(data=df_grouped_by_day_vessel, x='Date', y='All Engines Fuel Flow Rate (kg/h)', hue='Vessel Name', palette='Set1')

# Step 3: Set plot labels and title
plt.xlabel('Date')
plt.ylabel('Total Fuel Flow Rate (kg/h)')
plt.title('Total Fuel Flow Rate Over Time by Vessel (Grouped by Day)')
plt.xticks(rotation=45)
plt.legend(title='Vessel')

# Step 4: Display the plot
plt.tight_layout()
plt.show()
```


```{python}
#| label: Plot6
#| echo: false
#| message: false

# Define the engine power source columns to sum for each vessel
engine_power_sources = [
    'Main Engine 1 Fuel Flow Rate (kg/h)', 
    'Main Engine 2 Fuel Flow Rate (kg/h)', 
    'Main Engine 3 Fuel Flow Rate (kg/h)', 
    'Main Engine 4 Fuel Flow Rate (kg/h)'
]

# Calculate total engine power consumption for each vessel
engine_power_totals_vessel_1 = [df[df['Vessel Name'] == 'Vessel 1'][source].sum() for source in engine_power_sources]
engine_power_totals_vessel_2 = [df[df['Vessel Name'] == 'Vessel 2'][source].sum() for source in engine_power_sources]

# Create pie chart for Vessel 1
fig_engine_vessel_1 = go.Figure(data=[go.Pie(
    labels=engine_power_sources,
    values=engine_power_totals_vessel_1,
    hole=0.3,  # Create a donut chart by setting a hole
    textinfo='label+percent', 
    hoverinfo='label+value+percent',  # Show label, value, and percentage on hover
)])

# Update layout for Vessel 1
fig_engine_vessel_1.update_layout(
    title='Contribution of Engine Fuel Flow Rates to Total Fuel Consumption (kg/h) - Vessel 1',
    height=600,
    width=800,
    template='plotly_white'
)

# Show the plot for Vessel 1
fig_engine_vessel_1.show()

# Create pie chart for Vessel 2
fig_engine_vessel_2 = go.Figure(data=[go.Pie(
    labels=engine_power_sources,
    values=engine_power_totals_vessel_2,
    hole=0.3,  # Create a donut chart by setting a hole
    textinfo='label+percent', 
    hoverinfo='label+value+percent',  # Show label, value, and percentage on hover
)])

# Update layout for Vessel 2
fig_engine_vessel_2.update_layout(
    title='Contribution of Engine Fuel Flow Rates to Total Fuel Consumption (kg/h) - Vessel 2',
    height=600,
    width=800,
    template='plotly_white'
)

# Show the plot for Vessel 2
fig_engine_vessel_2.show()
```



```{python}
#| label: Plot7
#| echo: false
#| message: false

plt.figure(figsize=(12, 6))

sns.lineplot(data=df, x='Date', y='All Boiler Fuel Flow Rate (L/h)', hue='Vessel Name', palette='Set1')

# Step 3: Set plot labels and title
plt.xlabel('Date')
plt.ylabel('Total Boiler Fuel Flow Rate (L/h)')
plt.title('Total Boiler Fuel Flow Rate Over Time by Vessel')
plt.xticks(rotation=45)
plt.legend(title='Vessel')

# Step 4: Display the plot
plt.tight_layout()
plt.show()

```

```{python}
#| label: Plot8
#| echo: false
#| message: false

# Assuming you have a DataFrame grouped by date and vessel
plt.figure(figsize=(12, 6))

sns.lineplot(data=df_grouped_by_day_vessel, x='Date', y='All Boiler Fuel Flow Rate (L/h)', hue='Vessel Name', palette='Set1')

# Step 3: Set plot labels and title
plt.xlabel('Date')
plt.ylabel('Total Boiler Fuel Flow Rate (L/h)')
plt.title('Total Boiler Fuel Flow Rate Over Time by Vessel')
plt.xticks(rotation=45)
plt.legend(title='Vessel')

# Step 4: Display the plot
plt.tight_layout()
plt.show()

```

```{python}
#| label: Plot9
#| echo: false
#| message: false

# Calculate total boiler fuel flow for each vessel
boiler_source_totals_vessel_1 = [
    df[df['Vessel Name'] == 'Vessel 1']['Boiler 1 Fuel Flow Rate (L/h)'].sum(),
    df[df['Vessel Name'] == 'Vessel 1']['Boiler 2 Fuel Flow Rate (L/h)'].sum()
]

boiler_source_totals_vessel_2 = [
    df[df['Vessel Name'] == 'Vessel 2']['Boiler 1 Fuel Flow Rate (L/h)'].sum(),
    df[df['Vessel Name'] == 'Vessel 2']['Boiler 2 Fuel Flow Rate (L/h)'].sum()
]

# List of boiler names
boiler_sources = ['Boiler 1', 'Boiler 2']

# Create pie chart for Vessel 1
fig_boiler_vessel_1 = go.Figure(data=[go.Pie(
    labels=boiler_sources,
    values=boiler_source_totals_vessel_1,
    hole=0.3,  # Create a donut chart by setting a hole
    textinfo='label+percent',  # Show label and percentage
    hoverinfo='label+value+percent',  # Show label, value, and percentage on hover
)])

# Update layout for Vessel 1
fig_boiler_vessel_1.update_layout(
    title='Contribution of Boiler Fuel Flow Sources to Total Fuel Consumption (L/h) - Vessel 1',
    height=600,
    width=800,
    template='plotly_white'
)

# Show the plot for Vessel 1
fig_boiler_vessel_1.show()

# Create pie chart for Vessel 2
fig_boiler_vessel_2 = go.Figure(data=[go.Pie(
    labels=boiler_sources,
    values=boiler_source_totals_vessel_2,
    hole=0.3,  # Create a donut chart by setting a hole
    textinfo='label+percent',  # Show label and percentage
    hoverinfo='label+value+percent',  # Show label, value, and percentage on hover
)])

# Update layout for Vessel 2
fig_boiler_vessel_2.update_layout(
    title='Contribution of Boiler Fuel Flow Sources to Total Fuel Consumption (L/h) - Vessel 2',
    height=600,
    width=800,
    template='plotly_white'
)

# Show the plot for Vessel 2
fig_boiler_vessel_2.show()

```


```{python}
#| label: Plot10
#| echo: false
#| message: false

# Create scatter plot for Vessel 1
fig_speed_fuel_vessel_1 = px.scatter(
    df[df['Vessel Name'] == 'Vessel 1'],
    x='Speed Over Ground (knots)',  # Actual speed column name
    y='All Engines Fuel Flow Rate (kg/h)',  # Actual fuel consumption column name
    title='Speed vs. Fuel Consumption - Vessel 1',
    labels={
        'Speed Over Ground (knots)': 'Speed Over Ground (knots)',
        'All Engines Fuel Flow Rate (kg/h)': 'Fuel Consumption (kg/h)'
    },
    template='plotly_white'
)

# Customize the appearance of Vessel 1
fig_speed_fuel_vessel_1.update_traces(marker=dict(color='blue', opacity=0.6))  # Set color and opacity

# Show the plot for Vessel 1
fig_speed_fuel_vessel_1.show()

# Create scatter plot for Vessel 2
fig_speed_fuel_vessel_2 = px.scatter(
    df[df['Vessel Name'] == 'Vessel 2'],
    x='Speed Over Ground (knots)',  # Actual speed column name
    y='All Engines Fuel Flow Rate (kg/h)',  # Actual fuel consumption column name
    title='Speed vs. Fuel Consumption - Vessel 2',
    labels={
        'Speed Over Ground (knots)': 'Speed Over Ground (knots)',
        'All Engines Fuel Flow Rate (kg/h)': 'Fuel Consumption (kg/h)'
    },
    template='plotly_white'
)

# Customize the appearance of Vessel 2
fig_speed_fuel_vessel_2.update_traces(marker=dict(color='orange', opacity=0.6))  # Set color and opacity

# Show the plot for Vessel 2
fig_speed_fuel_vessel_2.show()

```

```{python}
#| label: Pearsoncoefficient for vessel1
#| echo: false
#| message: false
#| include: false


# Calculate Pearson correlation coefficient for Vessel 1
vessel_1_data = df[df['Vessel Name'] == 'Vessel 1']
pearson_corr_vessel_1, _ = pearsonr(
    vessel_1_data['Speed Over Ground (knots)'],
    vessel_1_data['All Engines Fuel Flow Rate (kg/h)']
)

pearson_corr_vessel_1

```

```{python}
#| label: Pearsson coefficient for vessel2
#| echo: false
#| message: false
#| include: false


# Calculate Pearson correlation coefficient for Vessel 1
vessel_2_data = df[df['Vessel Name'] == 'Vessel 2']
pearson_corr_vessel_2, _ = pearsonr(
    vessel_2_data['Speed Over Ground (knots)'],
    vessel_2_data['All Engines Fuel Flow Rate (kg/h)']
)

pearson_corr_vessel_2

```

```{python}
#| label: Plot11
#| echo: false
#| message: false


# Calculate Pearson correlation coefficient for Vessel 1
vessel_1_data = df[df['Vessel Name'] == 'Vessel 1']
pearson_corr_vessel_1_power, _ = pearsonr(
    vessel_1_data['Speed Over Ground (knots)'],
    vessel_1_data['Total Power Consumption (MW)']  # Replace with your actual power consumption column name
)

# Create scatter plot for Vessel 1
fig_speed_power_vessel_1 = px.scatter(
    vessel_1_data,
    x='Speed Over Ground (knots)',  # Actual speed column name
    y='Total Power Consumption (MW)',  # Actual power consumption column name
    title=f'Speed vs. Total Power Consumption - Vessel 1 (Pearson Correlation: {pearson_corr_vessel_1_power:.2f})',
    labels={
        'Speed Over Ground (knots)': 'Speed Over Ground (knots)',
        'Total Power Consumption (MW)': 'Total Power Consumption (MW)'
    },
    template='plotly_white'
)

# Customize the appearance of Vessel 1
fig_speed_power_vessel_1.update_traces(marker=dict(color='blue', opacity=0.6))  # Set color and opacity

# Show the plot for Vessel 1
fig_speed_power_vessel_1.show()

# Calculate Pearson correlation coefficient for Vessel 2
vessel_2_data = df[df['Vessel Name'] == 'Vessel 2']
pearson_corr_vessel_2_power, _ = pearsonr(
    vessel_2_data['Speed Over Ground (knots)'],
    vessel_2_data['Total Power Consumption (MW)']  # Replace with your actual power consumption column name
)

# Create scatter plot for Vessel 2
fig_speed_power_vessel_2 = px.scatter(
    vessel_2_data,
    x='Speed Over Ground (knots)',  # Actual speed column name
    y='Total Power Consumption (MW)',  # Actual power consumption column name
    title=f'Speed vs. Total Power Consumption - Vessel 2 (Pearson Correlation: {pearson_corr_vessel_2_power:.2f})',
    labels={
        'Speed Over Ground (knots)': 'Speed Over Ground (knots)',
        'Total Power Consumption (MW)': 'Total Power Consumption (MW)'
    },
    template='plotly_white'
)

# Customize the appearance of Vessel 2
fig_speed_power_vessel_2.update_traces(marker=dict(color='orange', opacity=0.6))  # Set color and opacity

# Show the plot for Vessel 2
fig_speed_power_vessel_2.show()

# Print Pearson correlation coefficients
print(f'Pearson correlation for Vessel 1 (Power Consumption): {pearson_corr_vessel_1_power:.2f}')
print(f'Pearson correlation for Vessel 2 (Power Consumption): {pearson_corr_vessel_2_power:.2f}')

```


## Impact of Sea Conditions

# Comparative Analysis

## Vessel Comparison

## Performance Trends 

# Key Performance Indicators

```{python}
#| label: kpi
#| echo: false
#| message: false
#| include: false

# Step 1: Create a new DataFrame
df_new = df.copy()

# Convert time columns to datetime
df_new['Start Time'] = pd.to_datetime(df_new['Start Time'])
df_new['End Time'] = pd.to_datetime(df_new['End Time'])

# Step 2: Calculate Operational Hours
df_new['Operational Hours'] = (df_new['End Time'] - df_new['Start Time']).dt.total_seconds() / 3600  # Convert seconds to hours

# Step 3: Calculate Total Power Produced (MW)
df_new['Total Power Produced (MW)'] = (
    df_new['Power Galley 1 (MW)'] +
    df_new['Power Galley 2 (MW)'] +
    df_new['Power Service (MW)'] +
    df_new['Diesel Generator 1 Power (MW)'] +
    df_new['Diesel Generator 2 Power (MW)'] +
    df_new['Diesel Generator 3 Power (MW)'] +
    df_new['Diesel Generator 4 Power (MW)'] +
    df_new['HVAC Chiller 1 Power (MW)'] +
    df_new['HVAC Chiller 2 Power (MW)'] +
    df_new['HVAC Chiller 3 Power (MW)'] +
    df_new['Scrubber Power (MW)'] +
    df_new['Propulsion Power (MW)'] +
    df_new['Port Side Propulsion Power (MW)'] +
    df_new['Starboard Side Propulsion Power (MW)'] +
    df_new['Bow Thruster 1 Power (MW)'] +
    df_new['Bow Thruster 2 Power (MW)'] +
    df_new['Bow Thruster 3 Power (MW)'] +
    df_new['Stern Thruster 1 Power (MW)'] +
    df_new['Stern Thruster 2 Power (MW)']
)

# Step 4: Calculate Total Fuel Consumed (kg/h)
df_new['Total Fuel Consumed (kg/h)'] = (
    df_new['Main Engine 1 Fuel Flow Rate (kg/h)'] +
    df_new['Main Engine 2 Fuel Flow Rate (kg/h)'] +
    df_new['Main Engine 3 Fuel Flow Rate (kg/h)'] +
    df_new['Main Engine 4 Fuel Flow Rate (kg/h)'] +
    df_new['All Boiler Fuel Flow Rate (L/h)']  # Convert to kg if necessary
)

# Step 5: Calculate Total Distance Traveled (nautical miles)
df_new['Total Distance Traveled (nautical miles)'] = df_new['Speed Over Ground (knots)'] * df_new['Operational Hours']

# Step 6: Calculate KPIs
kpi_data = df_new.groupby('Vessel Name').agg({
    'Total Power Produced (MW)': 'sum',
    'Total Fuel Consumed (kg/h)': 'sum',
    'Operational Hours': 'sum',
    'Total Distance Traveled (nautical miles)': 'sum'  # Include distance in aggregation
}).reset_index()

# Additional KPIs
kpi_data['Energy Efficiency Ratio (EER)'] = kpi_data['Total Power Produced (MW)'] / kpi_data['Total Fuel Consumed (kg/h)']
kpi_data['Operational Efficiency (MW/hour)'] = kpi_data['Total Power Produced (MW)'] / kpi_data['Operational Hours']
kpi_data['Fuel Efficiency (kg/MW)'] = kpi_data['Total Fuel Consumed (kg/h)'] / kpi_data['Total Power Produced (MW)']
kpi_data['Average Speed (knots)'] = kpi_data['Total Distance Traveled (nautical miles)'] / kpi_data['Operational Hours']

# Display KPIs
print(kpi_data[['Vessel Name', 'Energy Efficiency Ratio (EER)', 'Operational Efficiency (MW/hour)', 'Fuel Efficiency (kg/MW)', 'Average Speed (knots)']])

```

```{python}
#| label: Plot12 of kpi
#| echo: false
#| message: false


# Set the aesthetic style of the plots
sns.set(style="whitegrid")

# Step 1: Create a figure to hold multiple plots
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))
fig.suptitle('Cruise Ship KPIs Analysis', fontsize=16)

# Step 2: Plot Energy Efficiency Ratio (EER)
sns.barplot(x='Vessel Name', y='Energy Efficiency Ratio (EER)', data=kpi_data, ax=axes[0, 0], palette='viridis')
axes[0, 0].set_title('Energy Efficiency Ratio (EER)')
axes[0, 0].set_ylabel('EER (MW/kg)')
axes[0, 0].set_xticklabels(axes[0, 0].get_xticklabels(), rotation=45)

# Step 3: Plot Operational Efficiency
sns.barplot(x='Vessel Name', y='Operational Efficiency (MW/hour)', data=kpi_data, ax=axes[0, 1], palette='mako')
axes[0, 1].set_title('Operational Efficiency (MW/hour)')
axes[0, 1].set_ylabel('Operational Efficiency (MW/hour)')
axes[0, 1].set_xticklabels(axes[0, 1].get_xticklabels(), rotation=45)

# Step 4: Plot Fuel Efficiency
sns.barplot(x='Vessel Name', y='Fuel Efficiency (kg/MW)', data=kpi_data, ax=axes[1, 0], palette='plasma')
axes[1, 0].set_title('Fuel Efficiency (kg/MW)')
axes[1, 0].set_ylabel('Fuel Efficiency (kg/MW)')
axes[1, 0].set_xticklabels(axes[1, 0].get_xticklabels(), rotation=45)

# Step 5: Plot Average Speed
sns.barplot(x='Vessel Name', y='Average Speed (knots)', data=kpi_data, ax=axes[1, 1], palette='cividis')
axes[1, 1].set_title('Average Speed (knots)')
axes[1, 1].set_ylabel('Average Speed (knots)')
axes[1, 1].set_xticklabels(axes[1, 1].get_xticklabels(), rotation=45)

# Adjust layout
plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust title position
plt.show()



```



# Reference List 

Azur, M. J., Stuart, E. A., Frangakis, C., & Leaf, P. J. (2011). Multiple imputation by chained equations: what is
it and how does it work? International journal of methods in psychiatric research, 20(1), 40–49.
https://doi.org/10.1002/mpr.329

B.V, D. C., Directorate-General for Maritime Affairs and Fisheries                                          (European Commission), & Consulting, R. M. (1970, January 1). Good practices for sustainable cruise tourism. Publications Office of the EU. https://op.europa.eu/en/publication-detail/-/publication/664f158c-909c-11ed-b508-01aa75ed71a1 

Makaba, T. & Dogo, E. (2019). A Comparison of Strategies for Missing Values in Data on Machine Learning
Classification Algorithms. International Multidisciplinary Information Technology and Engineering
Conference (IMITEC), Vanderbijlpark, South Africa, pp. 1-7. https://ieeexplore.ieee.org/document/9015889
